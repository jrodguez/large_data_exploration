{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Create a new Jupyter notebook called 'SEDS-HW2.ipynb' and finish the in class excersize of creating a block of code to download the HCEPDB data, unzip it and load it into a data frame in Python (not using %% bash magic!) so that it works for a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of imports for the code\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "#First, we will check if the file exists to avoid downloading twice\n",
    "\n",
    "if os.path.exists('HCEPDB_moldata.zip'):\n",
    "    print('File already exists')\n",
    "else:\n",
    "    print('Continue with download')\n",
    "\n",
    "    #Now we will use the requests package to obtain the file from a URL\n",
    "\n",
    "    url = 'http://faculty.washington.edu/dacb/HCEPDB_moldata.zip'\n",
    "    req = requests.get(url)\n",
    "    assert req.status_code == 200 #This line of code will return an error if for some reason the download is unsuccessful\n",
    "    with open('HCEPDB_moldata.zip', 'wb') as f:\n",
    "        f.write(req.content)\n",
    "    \n",
    "    #Finally, we will use the zipfile package to extract the file before reading it with pandas\n",
    "\n",
    "    zf = zipfile.ZipFile('HCEPDB_moldata.zip')\n",
    "    data = pd.read_csv(zf.open('HCEPDB_moldata.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " I did not have the file in this particular directory, so the code continued with the download process and unzipped the file. Below is the data now being read in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES_str</th>\n",
       "      <th>stoich_str</th>\n",
       "      <th>mass</th>\n",
       "      <th>pce</th>\n",
       "      <th>voc</th>\n",
       "      <th>jsc</th>\n",
       "      <th>e_homo_alpha</th>\n",
       "      <th>e_gap_alpha</th>\n",
       "      <th>e_lumo_alpha</th>\n",
       "      <th>tmp_smiles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>655365</td>\n",
       "      <td>C1C=CC=C1c1cc2[se]c3c4occc4c4nsnc4c3c2cn1</td>\n",
       "      <td>C18H9N3OSSe</td>\n",
       "      <td>394.3151</td>\n",
       "      <td>5.161953</td>\n",
       "      <td>0.867601</td>\n",
       "      <td>91.567575</td>\n",
       "      <td>-5.467601</td>\n",
       "      <td>2.022944</td>\n",
       "      <td>-3.444656</td>\n",
       "      <td>C1=CC=C(C1)c1cc2[se]c3c4occc4c4nsnc4c3c2cn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1245190</td>\n",
       "      <td>C1C=CC=C1c1cc2[se]c3c(ncc4ccccc34)c2c2=C[SiH2]...</td>\n",
       "      <td>C22H15NSeSi</td>\n",
       "      <td>400.4135</td>\n",
       "      <td>5.261398</td>\n",
       "      <td>0.504824</td>\n",
       "      <td>160.401549</td>\n",
       "      <td>-5.104824</td>\n",
       "      <td>1.630750</td>\n",
       "      <td>-3.474074</td>\n",
       "      <td>C1=CC=C(C1)c1cc2[se]c3c(ncc4ccccc34)c2c2=C[SiH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21847</td>\n",
       "      <td>C1C=c2ccc3c4c[nH]cc4c4c5[SiH2]C(=Cc5oc4c3c2=C1...</td>\n",
       "      <td>C24H17NOSi</td>\n",
       "      <td>363.4903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>197.474780</td>\n",
       "      <td>-4.539526</td>\n",
       "      <td>1.462158</td>\n",
       "      <td>-3.077368</td>\n",
       "      <td>C1=CC=C(C1)C1=Cc2oc3c(c2[SiH2]1)c1c[nH]cc1c1cc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65553</td>\n",
       "      <td>[SiH2]1C=CC2=C1C=C([SiH2]2)C1=Cc2[se]ccc2[SiH2]1</td>\n",
       "      <td>C12H12SeSi3</td>\n",
       "      <td>319.4448</td>\n",
       "      <td>6.138294</td>\n",
       "      <td>0.630274</td>\n",
       "      <td>149.887545</td>\n",
       "      <td>-5.230274</td>\n",
       "      <td>1.682250</td>\n",
       "      <td>-3.548025</td>\n",
       "      <td>C1=CC2=C([SiH2]1)C=C([SiH2]2)C1=Cc2[se]ccc2[Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>720918</td>\n",
       "      <td>C1C=c2c3ccsc3c3[se]c4cc(oc4c3c2=C1)C1=CC=CC1</td>\n",
       "      <td>C20H12OSSe</td>\n",
       "      <td>379.3398</td>\n",
       "      <td>1.991366</td>\n",
       "      <td>0.242119</td>\n",
       "      <td>126.581347</td>\n",
       "      <td>-4.842119</td>\n",
       "      <td>1.809439</td>\n",
       "      <td>-3.032680</td>\n",
       "      <td>C1=CC=C(C1)c1cc2[se]c3c4sccc4c4=CCC=c4c3c2o1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         SMILES_str   stoich_str  \\\n",
       "0   655365          C1C=CC=C1c1cc2[se]c3c4occc4c4nsnc4c3c2cn1  C18H9N3OSSe   \n",
       "1  1245190  C1C=CC=C1c1cc2[se]c3c(ncc4ccccc34)c2c2=C[SiH2]...  C22H15NSeSi   \n",
       "2    21847  C1C=c2ccc3c4c[nH]cc4c4c5[SiH2]C(=Cc5oc4c3c2=C1...   C24H17NOSi   \n",
       "3    65553   [SiH2]1C=CC2=C1C=C([SiH2]2)C1=Cc2[se]ccc2[SiH2]1  C12H12SeSi3   \n",
       "4   720918       C1C=c2c3ccsc3c3[se]c4cc(oc4c3c2=C1)C1=CC=CC1   C20H12OSSe   \n",
       "\n",
       "       mass       pce       voc         jsc  e_homo_alpha  e_gap_alpha  \\\n",
       "0  394.3151  5.161953  0.867601   91.567575     -5.467601     2.022944   \n",
       "1  400.4135  5.261398  0.504824  160.401549     -5.104824     1.630750   \n",
       "2  363.4903  0.000000  0.000000  197.474780     -4.539526     1.462158   \n",
       "3  319.4448  6.138294  0.630274  149.887545     -5.230274     1.682250   \n",
       "4  379.3398  1.991366  0.242119  126.581347     -4.842119     1.809439   \n",
       "\n",
       "   e_lumo_alpha                                     tmp_smiles_str  \n",
       "0     -3.444656        C1=CC=C(C1)c1cc2[se]c3c4occc4c4nsnc4c3c2cn1  \n",
       "1     -3.474074  C1=CC=C(C1)c1cc2[se]c3c(ncc4ccccc34)c2c2=C[SiH...  \n",
       "2     -3.077368  C1=CC=C(C1)C1=Cc2oc3c(c2[SiH2]1)c1c[nH]cc1c1cc...  \n",
       "3     -3.548025  C1=CC2=C([SiH2]1)C=C([SiH2]2)C1=Cc2[se]ccc2[Si...  \n",
       "4     -3.032680       C1=CC=C(C1)c1cc2[se]c3c4sccc4c4=CCC=c4c3c2o1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "\n",
    "## Run the code you put together for the three files below.  Use Markdown between the set of cells to offset and explain your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code that was run above is fully functional for a single file. We would like to utilize the code to now open these three new files below.\n",
    "\n",
    "| URL | filename | csv_filename |\n",
    "|-----|----------|--------------|\n",
    "| http://faculty.washington.edu/dacb/HCEPDB_moldata_set1.zip | HCEPDB_moldata_set1.zip | HCEPDB_moldata_set1.csv |\n",
    "| http://faculty.washington.edu/dacb/HCEPDB_moldata_set2.zip | HCEPDB_moldata_set2.zip | HCEPDB_moldata_set2.csv |\n",
    "| http://faculty.washington.edu/dacb/HCEPDB_moldata_set3.zip | HCEPDB_moldata_set3.zip | HCEPDB_moldata_set3.csv |\n",
    "\n",
    "Without requiring much more effort, it is possible to replicate the above code three times to download the three files individually by changing the filenames and URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('HCEPDB_moldata_set1.zip'):\n",
    "    print('File already exists')\n",
    "else:\n",
    "    print('Continue with download')\n",
    "\n",
    "    url = 'http://faculty.washington.edu/dacb/HCEPDB_moldata_set1.zip'\n",
    "    req = requests.get(url)\n",
    "    assert req.status_code == 200 \n",
    "    with open('HCEPDB_moldata_set1.zip', 'wb') as f:\n",
    "        f.write(req.content)\n",
    "    \n",
    "    zf = zipfile.ZipFile('HCEPDB_moldata_set1.zip')\n",
    "    df1 = pd.read_csv(zf.open('HCEPDB_moldata_set1.csv'))\n",
    "\n",
    "    df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('HCEPDB_moldata_set2.zip'):\n",
    "    print('File already exists')\n",
    "else:\n",
    "    print('Continue with download')\n",
    "\n",
    "    url = 'http://faculty.washington.edu/dacb/HCEPDB_moldata_set2.zip'\n",
    "    req = requests.get(url)\n",
    "    assert req.status_code == 200 \n",
    "    with open('HCEPDB_moldata_set2.zip', 'wb') as f:\n",
    "        f.write(req.content)\n",
    "    \n",
    "    zf = zipfile.ZipFile('HCEPDB_moldata_set2.zip')\n",
    "    df2 = pd.read_csv(zf.open('HCEPDB_moldata_set2.csv'))\n",
    "\n",
    "    df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists('HCEPDB_moldata_set3.zip'):\n",
    "    print('File already exists')\n",
    "else:\n",
    "    print('Continue with download')\n",
    "\n",
    "    url = 'http://faculty.washington.edu/dacb/HCEPDB_moldata_set3.zip'\n",
    "    req = requests.get(url)\n",
    "    assert req.status_code == 200 \n",
    "    with open('HCEPDB_moldata_set3.zip', 'wb') as f:\n",
    "        f.write(req.content)\n",
    "    \n",
    "    zf = zipfile.ZipFile('HCEPDB_moldata_set3.zip')\n",
    "    df3 = pd.read_csv(zf.open('HCEPDB_moldata_set3.csv'))\n",
    "\n",
    "    df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "\n",
    "## In a separate set of cells, use lists, tuples, dictionaries, for loops, if statements, and whatever other tasty Python bits you want to run your code on the three files so that you don't replicate code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, the code in part one only works for a single indivdual file. In part two we essentially copied the code three times and modified the filenames to download the three new files seperately. While functional, this is not the most efficient and savy technique available. Imagine needing to download 10 or 20 files and having to copy/paste and modify the url's for each one. Now in this part, we will modify the code developed in part one to download all three files without needing to replicate the code each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,  we will create a set of lists that contain the zip filenames and urls for each file set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Since the zipfile function only works for a single file, we will not be using that package or the csv filenames. Instead, pandas is able to read zip files directly, so we will use that later on. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of zip files\n",
    "zip_list = ['HCEPDB_moldata_set1.zip','HCEPDB_moldata_set2.zip','HCEPDB_moldata_set3.zip']\n",
    "\n",
    "#list of URLs\n",
    "url_list = ['http://faculty.washington.edu/dacb/HCEPDB_moldata_set1.zip',\n",
    "        'http://faculty.washington.edu/dacb/HCEPDB_moldata_set2.zip',\n",
    "        'http://faculty.washington.edu/dacb/HCEPDB_moldata_set3.zip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will add a for loop into the first part of the code that checks whether or not the file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists\n",
      "File already exists\n",
      "File already exists\n"
     ]
    }
   ],
   "source": [
    "for files in zip_list:\n",
    "    if os.path.exists(files):\n",
    "        print('File already exists')\n",
    "    else:\n",
    "        print('Continue with download')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated, the files already exist from what we did in Part 2. The rest of the code will assume a case where we indeed did not download the files previously. This would continue directly below the last line of code above in cell 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>SMILES_str</th>\n",
       "      <th>stoich_str</th>\n",
       "      <th>mass</th>\n",
       "      <th>pce</th>\n",
       "      <th>voc</th>\n",
       "      <th>jsc</th>\n",
       "      <th>e_homo_alpha</th>\n",
       "      <th>e_gap_alpha</th>\n",
       "      <th>e_lumo_alpha</th>\n",
       "      <th>tmp_smiles_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>927662</td>\n",
       "      <td>C1C(=Cc2cnc3c4sccc4c4nsnc4c3c12)c1scc2ccoc12</td>\n",
       "      <td>C20H9N3OS3</td>\n",
       "      <td>403.5091</td>\n",
       "      <td>4.279665</td>\n",
       "      <td>0.787542</td>\n",
       "      <td>83.634150</td>\n",
       "      <td>-5.387542</td>\n",
       "      <td>2.082774</td>\n",
       "      <td>-3.304768</td>\n",
       "      <td>c1cc2c3nsnc3c3c4CC(=Cc4cnc3c2s1)c1scc2ccoc12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>665520</td>\n",
       "      <td>C1C=Cc2c1csc2-c1cc2ccc3c4[se]ccc4c4nsnc4c3c2cn1</td>\n",
       "      <td>C22H11N3S2Se</td>\n",
       "      <td>460.4419</td>\n",
       "      <td>5.845911</td>\n",
       "      <td>0.891818</td>\n",
       "      <td>100.884304</td>\n",
       "      <td>-5.491818</td>\n",
       "      <td>1.960913</td>\n",
       "      <td>-3.530905</td>\n",
       "      <td>c1cc2c3nsnc3c3c(ccc4cc(ncc34)-c3scc4CC=Cc34)c2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2402229</td>\n",
       "      <td>c1[nH]cc2c1ccc1c3nsnc3c3c(oc4cc(-c5nccc6nsnc56...</td>\n",
       "      <td>C25H10N6O2S2</td>\n",
       "      <td>490.5260</td>\n",
       "      <td>8.873984</td>\n",
       "      <td>0.563516</td>\n",
       "      <td>242.359361</td>\n",
       "      <td>-5.163516</td>\n",
       "      <td>1.256386</td>\n",
       "      <td>-3.907130</td>\n",
       "      <td>c1cc2c3nsnc3c3c(oc4cc(-c5nccc6nsnc56)c5cocc5c3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42936</td>\n",
       "      <td>[SiH2]1C(=Cc2cnc3c4occc4c4nsnc4c3c12)c1ncncn1</td>\n",
       "      <td>C16H8N6OSSi</td>\n",
       "      <td>360.4322</td>\n",
       "      <td>5.051803</td>\n",
       "      <td>1.565185</td>\n",
       "      <td>49.673911</td>\n",
       "      <td>-6.165185</td>\n",
       "      <td>2.389070</td>\n",
       "      <td>-3.776114</td>\n",
       "      <td>c1cc2c3nsnc3c3c4[SiH2]C(=Cc4cnc3c2o1)c1ncncn1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1910714</td>\n",
       "      <td>[SiH2]1C(=Cc2c1c1c3nsnc3c3cc[se]c3c1c1c[nH]cc2...</td>\n",
       "      <td>C21H10N6S2SeSi</td>\n",
       "      <td>517.5300</td>\n",
       "      <td>9.127722</td>\n",
       "      <td>0.651534</td>\n",
       "      <td>215.611879</td>\n",
       "      <td>-5.251534</td>\n",
       "      <td>1.394143</td>\n",
       "      <td>-3.857392</td>\n",
       "      <td>c1cc2c3nsnc3c3c4[SiH2]C(=Cc4c4c[nH]cc4c3c2[se]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         SMILES_str      stoich_str  \\\n",
       "0   927662       C1C(=Cc2cnc3c4sccc4c4nsnc4c3c12)c1scc2ccoc12      C20H9N3OS3   \n",
       "1   665520    C1C=Cc2c1csc2-c1cc2ccc3c4[se]ccc4c4nsnc4c3c2cn1    C22H11N3S2Se   \n",
       "2  2402229  c1[nH]cc2c1ccc1c3nsnc3c3c(oc4cc(-c5nccc6nsnc56...    C25H10N6O2S2   \n",
       "3    42936      [SiH2]1C(=Cc2cnc3c4occc4c4nsnc4c3c12)c1ncncn1     C16H8N6OSSi   \n",
       "4  1910714  [SiH2]1C(=Cc2c1c1c3nsnc3c3cc[se]c3c1c1c[nH]cc2...  C21H10N6S2SeSi   \n",
       "\n",
       "       mass       pce       voc         jsc  e_homo_alpha  e_gap_alpha  \\\n",
       "0  403.5091  4.279665  0.787542   83.634150     -5.387542     2.082774   \n",
       "1  460.4419  5.845911  0.891818  100.884304     -5.491818     1.960913   \n",
       "2  490.5260  8.873984  0.563516  242.359361     -5.163516     1.256386   \n",
       "3  360.4322  5.051803  1.565185   49.673911     -6.165185     2.389070   \n",
       "4  517.5300  9.127722  0.651534  215.611879     -5.251534     1.394143   \n",
       "\n",
       "   e_lumo_alpha                                     tmp_smiles_str  \n",
       "0     -3.304768       c1cc2c3nsnc3c3c4CC(=Cc4cnc3c2s1)c1scc2ccoc12  \n",
       "1     -3.530905  c1cc2c3nsnc3c3c(ccc4cc(ncc34)-c3scc4CC=Cc34)c2...  \n",
       "2     -3.907130  c1cc2c3nsnc3c3c(oc4cc(-c5nccc6nsnc56)c5cocc5c3...  \n",
       "3     -3.776114      c1cc2c3nsnc3c3c4[SiH2]C(=Cc4cnc3c2o1)c1ncncn1  \n",
       "4     -3.857392  c1cc2c3nsnc3c3c4[SiH2]C(=Cc4c4c[nH]cc4c3c2[se]...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For loop to download all the files given the list of urls\n",
    "for urls in url_list:\n",
    "    for zips in zip_list:\n",
    "        req = requests.get(urls)\n",
    "        assert req.status_code == 200 \n",
    "        with open(zips, 'wb') as f:\n",
    "            f.write(req.content)\n",
    "        \n",
    "    #For loop to open and read the zip files directly using pandas\n",
    "    for new_files in zip_list:\n",
    "        HCEDB_sets = pd.read_csv(new_files, compression = 'zip')\n",
    "\n",
    "HCEDB_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
